{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1VQoGVNJO-i1DNBkAxMT51Z2duH1wtxfy",
      "authorship_tag": "ABX9TyNppiyPogeiURuobYmLfqT/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Usamamalik11/Darth-Vader/blob/master/Text%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S623yN8NTfSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/Consumer_Complaints.csv', nrows = 10000) ## Use larger dataset for more accurate results. I have only taken 10000 rows as I was running out of memory.\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1jvq5PacyMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cleaning and Preprocessing the data\n",
        "\n",
        "from io import StringIO ## In case I want a file-like object that ACTS like a file, but is writing to an in-memory string buffer.\n",
        "col = ['Product', 'Consumer complaint narrative']\n",
        "df = df[col]\n",
        "df = df[pd.notnull(df['Consumer complaint narrative'])]   ## removes nan's\n",
        "df.columns = ['Product', 'Consumer_complaint_narrative']   ## naming the columns \n",
        "df['category_id'] = df['Product'].factorize()[0]         ## will categorize acording to product\n",
        "category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')   ## a smaller table containing categorical products\n",
        "category_to_id = dict(category_id_df.values)    ## creates a dictionary with mapping from product to category_id\n",
        "id_to_category = dict(category_id_df[['category_id', 'Product']].values) ## creates a dictionary with mapping from category_id to product\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5quRyxUc30v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Plotting the data\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(8,6))## width and height in inches\n",
        "df.groupby('Product').Consumer_complaint_narrative.count().plot.bar(ylim=0)## counts cases of each product and plots them in bars\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xp_SGFkdKlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Vectorizing the data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "features = tfidf.fit_transform(df.Consumer_complaint_narrative).toarray()\n",
        "labels = df.category_id\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgKbf4p0dme-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   sublinear_df is set to True to use a logarithmic form for frequency.\n",
        "\n",
        "\n",
        "*   min_df is the minimum numbers of documents a word must be present in to be kept.\n",
        "\n",
        "*   norm is set to l2, to ensure all our feature vectors have a euclidian norm of 1.\n",
        "*   ngram_range is set to (1, 2) to indicate that we want to consider both unigrams and bigrams.\n",
        "\n",
        "\n",
        "*   stop_words is set to \"english\" to remove all common pronouns (\"a\", \"the\", ...) to reduce the number of noisy features \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuDmZMttjZJ-",
        "colab_type": "text"
      },
      "source": [
        "### We can use sklearn.feature_selection.chi2 to find the terms that are the most correlated with each of the products."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OgSN-F1ji8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "\n",
        "N = 2\n",
        "for Product, category_id in sorted(category_to_id.items()):\n",
        "  features_chi2 = chi2(features, labels == category_id)\n",
        "  indices = np.argsort(features_chi2[0])\n",
        "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
        "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
        "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
        "  print(\"# '{}':\".format(Product))\n",
        "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
        "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdDL2Y7xY0K",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   To train supervised classifiers, we first transformed the “Consumer complaint narrative” into a vector of numbers. We explored vector representations such as TF-IDF weighted vectors.\n",
        "\n",
        "*   After having this vector representations of the text we can train supervised classifiers to train unseen “Consumer complaint narrative” and predict the “product” on which they fall.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmr8A2FyExN",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSHRWPm8yKPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Consumer_complaint_narrative'], df['Product'], random_state = 0)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v2xxAN50R2L",
        "colab_type": "text"
      },
      "source": [
        "Let's make a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7wboHEP0u_N",
        "colab_type": "code",
        "outputId": "365d9f16-4f1c-4477-dc3f-53896c92e90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(clf.predict(count_vect.transform([\"I am disputing the inaccurate information the Chex-Systems has on my credit report. I initially submitted a police report on XXXX/XXXX/16 and Chex Systems only deleted the items that I mentioned in the letter and not all the items that were actually listed on the police report. In other words they wanted me to say word for word to them what items were fraudulent. The total disregard of the police report and what accounts that it states that are fraudulent. If they just had paid a little closer attention to the police report I would not been in this position now and they would n't have to research once again. I would like the reported information to be removed : XXXX XXXX XXXX\"])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Credit reporting, credit repair services, or other personal consumer reports']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqnCqgY071n",
        "colab_type": "code",
        "outputId": "92a0044f-7494-4c86-8a17-e2e9e73e1559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "df[df['Consumer_complaint_narrative'] == \"I am disputing the inaccurate information the Chex-Systems has on my credit report. I initially submitted a police report on XXXX/XXXX/16 and Chex Systems only deleted the items that I mentioned in the letter and not all the items that were actually listed on the police report. In other words they wanted me to say word for word to them what items were fraudulent. The total disregard of the police report and what accounts that it states that are fraudulent. If they just had paid a little closer attention to the police report I would not been in this position now and they would n't have to research once again. I would like the reported information to be removed : XXXX XXXX XXXX\"]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Consumer_complaint_narrative</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Product, Consumer_complaint_narrative, category_id]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV8Gcl7Q9_Jz",
        "colab_type": "text"
      },
      "source": [
        "We will evaluate the following four models:\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   (Multinomial) Naive Bayes\n",
        "\n",
        "*   Linear Support Vector Machine\n",
        "*   Random Forest\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e85ZTlc-YHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "models = [\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(),\n",
        "    LogisticRegression(random_state=0),\n",
        "]\n",
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "entries = []\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy))\n",
        "\n",
        "##creating a data frame for model name, fold number and corresponding accuracy\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
        "\n",
        "## plotted in two different ways \n",
        "import seaborn as sns \n",
        "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
        "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
        "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72gYY76LmUya",
        "colab_type": "code",
        "outputId": "d409da8a-3037-4865-f26a-0f8f32318482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cv_df.groupby('model_name').accuracy.mean() ## finding mean of accuracies of 5 folds"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_name\n",
              "LinearSVC                 0.785254\n",
              "LogisticRegression        0.733512\n",
              "MultinomialNB             0.543499\n",
              "RandomForestClassifier    0.480312\n",
              "Name: accuracy, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARtGDb66nfRj",
        "colab_type": "text"
      },
      "source": [
        "We can see that LinearSVC is the best model in this case to as it shows grater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFlbpoqmnrdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinearSVC()\n",
        "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
        "            xticklabels=category_id_df.Product.values, yticklabels=category_id_df.Product.values)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmv7Bd8QXT6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av-JXtztZTmj",
        "colab_type": "text"
      },
      "source": [
        "Let's see what misclassifications are caused by"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srkz6r74ZhBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display\n",
        "for predicted in category_id_df.category_id:\n",
        "  for actual in category_id_df.category_id:\n",
        "    if predicted != actual and conf_mat[actual, predicted] >= 10:\n",
        "      print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], id_to_category[predicted], conf_mat[actual, predicted]))\n",
        "      display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['Product', 'Consumer_complaint_narrative']])\n",
        "      print('')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkVnBp-c75y",
        "colab_type": "text"
      },
      "source": [
        "Again, we use the chi-squared test to find the terms that are the most correlated with each of the categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrjHumvjc_Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(features, labels)\n",
        "N = 2\n",
        "for Product, category_id in sorted(category_to_id.items()):\n",
        "  indices = np.argsort(model.coef_[category_id])\n",
        "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
        "  unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
        "  bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
        "  print(\"# '{}':\".format(Product))\n",
        "  print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n",
        "  print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8W8vJpReIop",
        "colab_type": "text"
      },
      "source": [
        "Finally, we print out the classification report for each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwFsytKzeJzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=df['Product'].unique()))## target names here are just labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}